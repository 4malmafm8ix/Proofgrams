% Load required themes and packages.
\documentclass{beamer}
\usepackage{mdframed}

\usetheme{Pittsburgh}
\usecolortheme{default}
\useinnertheme{default}
\useoutertheme{default}
\usefonttheme{structurebold}

% Import the necessary preamble for the document. 
\usepackage{../proofsPrograms}

% Bibliography
\usepackage[style=alphabetic]{biblatex}
\addbibresource{../proofsPrograms.bib} 
% In case of error: check the file path!
% the ../../ acts to jump back to files in path.
% Command line sequence:
%   pdflatex *filename* without .tex
%   biber *filename* without .bib
%   pdflatex *filename* without .tex

% Remove navigation bar
\beamertemplatenavigationsymbolsempty
\setbeamertemplate{footline}[frame number]

% Definition format options. 
\newtheoremstyle{indentDefn}
{\topsep} % Space above
{\topsep} % Space below
{\it} % Body font
{2cm} % Indent amount
{\bf} % Theorem head font
{:} % Punctuation after theorem head
{0.5em} % Space after theorem head
{} % Theorem head spec

\theoremstyle{indentDefn} \newtheorem{defn}[]{Definition}

\title{Simply Typed $\lambda$-Calculus}
\subtitle{Curry-Howard Correspondence}
\author{MATH230}
\institute{Te Kura P\=angarau \\ Te Whare W\=ananga o Waitaha}
\date{}

% Document body starts here.
\begin{document}


% Title frame
\begin{frame}

  \titlepage

\end{frame}

% Table of contents page
\begin{frame}
  \frametitle{Outline}

  \tableofcontents

\end{frame}

\section{Type Theory}

\begin{frame}
  \frametitle{Motivation}

  	Type theory was originally formulated by Bertrand Russell and Gottlob Frege as a reaction to set theoretic paradoxes see the \href{https://plato.stanford.edu/entries/type-theory/}{Stanford Encyclopaedia article} on Type Theory for more on the historical development of the field. 
    
    Alonso Church introduced it to the $\lambda$-calculus as a way to avoid unending meaningless computation, to ensure that computations don't get stuck. 

    %%%% Make this comment in lecture. Not needed in notes. 
    % We see this today in modern programming languages when we get errors like these thrown at us: 

    % [Enter Python type error here]

    Consider the following program in the $\lambda$-calculus:

    % This will beta-reduce predictably if f,g are Church numerals. 
    % But what will it do if they're not? 

    $$\lambda f. \ \lambda g. \ \text{COND} \ (\text{EQUAL?} \ f \ g) \ (\text{SUCC} \ f) \ (\text{SUCC} \ g) $$

    \vspace{2cm}

\end{frame}

\begin{frame}
	\frametitle{Typed Languages}

  In order to get around this Church and others realised the $\lambda$-calculus should be augmented with type structure. 

  In typed $\lambda$-calculi each $\lambda$-term must be given an explicit type. This requires deciding at the outset the following: 

  \begin{itemize}
    \item Base types e.g. Int, Bool, [Int] etc. 
    \item Type constructors i.e. how to build new types from old.
  \end{itemize}

  These are language design choices: different type theories (programming languages) will have different base types and allow different type constructors. 

  In this course we will primarily be interested in type constructors and writing programs, rather than specifying the nature of any particular type. We will follow \href{https://www.cs.kent.ac.uk/people/staff/sjt/TTFP/}{Type Theory and Functional Programming, Thompson}. 

\end{frame}

\begin{frame}
  \frametitle{Type Declarations}

  Given a set of base types, $\mathcal{B} = \{A,B,C,\dots\}$
  
  \begin{center}
  
  	A B C $\dots$ : Type
  
  \end{center}
  
  We must associate any variable $a,b,c,\dots$ in a program to a specific type. We use capital English letters for type-variables and lower-case English letters for term-variables. 

  We write type declarations as follows: 
  
  $$ x : A \hspace{1cm} \text{ the term x is of type A}$$

  % The empty context is another example. 
  % Context can be thought of as "global" assignments. 
  % Later Gamma will have more interesting lambda terms in it. 

  \vspace{30mm}

\end{frame}

\begin{frame}
	\frametitle{Function Type: Formation}

  The $\lambda$-calculus is closed under abstraction and application, so we need a way to assign types to these $\lambda$-terms. 
  
  We have been interpreting $\lambda$-terms as functions, so we close our set of types under the following operation: if $A,B$ are types, then $(A\to B)$ is also a type, called a function type. 
  
  \vspace{5mm}
  
  \begin{center}
  	$\begin{array}{c}
  		\infer[]{A \to B  \ : \ \text{Type}}
  			{A  \ : \ \text{Type}
  			\hspace{10mm}&\hspace{10mm}
  			 B  \ : \ \text{Type}}
  	\end{array}$  
  \end{center}

  {\bf Examples}

  \vspace{30mm}

  % The terms of the simply typed $\lambda$-calculus are either variables or one of the following two forms: 

  % {\bf Abstraction: } If $x: A$ and $e: B$, then $(\lambda x:A. \ e) : (A\to B)$

  % {\bf Application: } If $f : A \to B$ and $a : A$, then $(f \ a) : B$

  % \vspace{0.5cm}

\end{frame}

\begin{frame}
  \frametitle{Simply Typed Programs}

  As in the untyped $\lambda$-calculus, programs are written by constructing $\lambda$-terms, and composing different $\lambda$-terms together. 
  
  Now we have to be careful to only create and combine terms according to the typing rules for variables, abstraction, and application. 

  We will now develop a calculus for programming in the simply typed $\lambda$-calculus so that we don't have any type errors. 

	\vspace{50mm}

\end{frame}

\begin{frame}
  \frametitle{Type Contexts}

  We typically write programs in the context of some type declarations. We denote the set of type declarations $\Sigma$ throughout the notes. 

  $$\Sigma = \{x : A, \ f : A \to B, \ g : (A \to B) \to C\}$$
  % Type contexts can be thought of like modules you import at the start of a program.

	$\Sigma$ might be thought of has global variables, or modules/libraries, that we can use in our programs.

 	We are interested in a number of questions in relation to the construction of terms, inhabiting particular types, in particular contexts. 
 	
 	\vspace{30mm}

\end{frame}

\begin{frame}
  \frametitle{Typing Derivation: Variables}

  If $x : A$ is a type declaration in a type context $\Sigma$, then we can always call that term in a program. 

  $$\Sigma, x : A \ \vdash \ x : A$$

  \vspace{10mm}

  \begin{center}
    $\begin{array}{c}
        \infer[\text{Var}]{x : A}{}
    \end{array}$
  \end{center}

  % You can always call on terms declared in the type context. 
  \vspace{40mm}

\end{frame}

\begin{frame}
  \frametitle{Function Type: Destructor}

  If we can write a function type $f: A \to B$ in a type context $\Sigma$ and we have a term of type $x : A$ in the same context $\Sigma$, then we can obtain the term $f \ x : B$ from the same context $\Sigma$. 

  If $\Sigma, \ f : A \to B, \ x : A \ \vdash \ f \ x : B$ by function application.

  \vspace{10mm}

  \begin{center}
    $\begin{array}{c}
        \infer[\text{App}]{(f \ x) : B}
          {f : A \to B \hspace{0.5cm} & \hspace{0.5cm} x : A}
    \end{array}$
  \end{center}

\vspace{30mm}

\end{frame}

\begin{frame}
  \frametitle{Function Type: Constructor}

  If we can derive a term $e : B$, which may contain the free variable $a:A$, from the context $\Sigma$, then we may \emph{abstract over the} $a : A$, to get the term $(\lambda x : A. \ e) : A \to B$ in the context $\Sigma \backslash \{a:A\}$ \emph{without the declaration} $a : A$. 
  
  Note: the term $x$ may appear free in the the body $e$ of the abstraction. 

  If $\Sigma, x : A \vdash e : B$, then $\Sigma \vdash (\lambda x : A. \ e) : A \to B$

  \vspace{5mm}

	\begin{center}		
		$\begin{array}{c}		
			\infer[\lambda 1]{\lambda x:A. \ e \ : \ A \to B}
				{\begin{array}{c} \Sigma, \cancel{x \ : \ A} \\ \mathcal{D} \\ e \ : \ B \end{array}}
		\end{array}$
	\end{center}
  % If you can write a program that depends on an (arbitary) global variable, 
  % then you can take that global variable as input to a different function. 
  
  \vspace{20mm}

\end{frame}

\begin{frame}
  \frametitle{Well-Typed Terms}

  We say a $\lambda$-term $t$ is well-typed, of type $T$, in the context $\Sigma$ if there exists a derivation of $t$ following the typing derivations above which shows $t : T$. We denote this using the notation:

  $$\Sigma \ \vdash \ t \ : \ T$$

  {\bf Example} $$f : A \to B, \ a : A \ \vdash \ (f \ a) \ : \ B$$

  \vspace{3cm}

\end{frame}

\begin{frame}
  \frametitle{Inhabited Types}

  We a say type $T$ is inhabited relative to a context $\Sigma$ if there exists a $\lambda$-term $t : T$ that can be derived from $\Sigma$ according to the typing derivations above. 

  $$\Sigma \ \vdash \ T$$
  
  This is the same idea as the previous slide, now with the emphasis on the type rather than the particular term.

  {\bf Example} $$f : A \to B, \ a : A \ \vdash \ B$$

  \vspace{30mm}

\end{frame}

\begin{frame}
  \frametitle{I Combinator}

  Show that the following type is inhabited: 

  $$ \vdash \ P \to P$$

  \vspace{70mm}
\end{frame}


\begin{frame}
  \frametitle{Guiding Questions}

  We may be tasked with any one of the following questions. If we are given a program, can we show it is well-typed? What context is required to do so? One might instead have a type and want to show that there is a program of that type.

  \begin{center}
    $\begin{array}{l l l l l l}
      \Sigma & \vdash & ? & : & T & \hspace{1cm} \text{Type inhabited relative to a context} \\
      \ & \vdash & ? & : & T & \hspace{1cm} \text{Type inhabited} \\
      \Sigma & \vdash & t & : & ? & \hspace{1cm} \text{Term well-typed relative to a context} \\
      \ & \vdash & t & : & ? & \hspace{1cm} \text{Term well-typed} \\
      ? & \vdash & t & : & T & \hspace{1cm} \text{Find a context} \\
      ? & \vdash & ? & : & ? & \hspace{1cm} \text{Find a context with a term of some type}
    \end{array}$
\end{center}

\vspace{50mm}

\end{frame}

\begin{frame}
  \frametitle{K Combinator}

  Show that the following type is inhabited:

  $$  \vdash \ P \to (Q \to P)$$

  \vspace{70mm}
\end{frame}

\begin{frame}
	\frametitle{S Combinator}
	% Show, by ad hoc means, that the $S$ combinator is well typed. 
	
	Prove that the \textbf{S} combinator can be well-typed: 	
	$$\textbf{S}:= \ \lambda x. \ \lambda y. \ \lambda z. \ x \ z \ (y \ z)$$
	
	% Both x y are function types that have the same domain, that of term z. 
	% Set z : A
	% The codomain of y has to the domain of (x \ z) 
	% Set this to be B. 
	% z : A and y : A -> B
	% This leaves one free type variable C for x : A -> (B -> C)
	% Overall this means the return type of S is C. 
	% S : (A -> B -> C) -> (A -> B) -> (A -> C)
	
	\vspace{60mm}

\end{frame}

\begin{frame}
	\frametitle{S Combinator}
	% Show, using a typing derivation, that the $S$ combinator is well typed.
	
	Prove that the \textbf{S} combinator can be well-typed: 	
	$$\textbf{S}:= \ \lambda x. \ \lambda y. \ \lambda z. \ x \ z \ (y \ z)$$
	
	% On this slide give a typing derivation of the type from the previous slide.
	
	\vspace{60mm}
	
	
\end{frame}

\begin{frame}
  \frametitle{Example}

  Show that the following type is inhabited:
  $$ \vdash \ (A \to B) \to (B \to C) \to (A \to C)$$

  \vspace{70mm}
\end{frame}

\begin{frame}
  \frametitle{Explicit Lambda Types}

  These $\lambda$-terms with their type annotations can be become unwieldy quickly. We can make them shorter by dropping explicit mention of the type of the variable in an abstraction. Since this information is in the type signature of the term, we do not lose anything by doing this. 
  
  \tiny{$$\lambda x : (A \to B \to C). \ \lambda y : (A \to B). \ \lambda z : A. \ x \ z \ (y \ z) \ : (A \to B \to C) \to (A \to B) \to A \to C$$}

  \vspace{50mm}

\end{frame}

\section{Curry-Howard Correspondence}

\begin{frame}
  \frametitle{Motivation}

  William Howard published \emph{The Formulae-as-Types Notion of Construction} in 1980 with the ultimate goal

  \emph{... to develop a notion of construction suitable for the interpretation of intuitionistic mathematics.}

  By intuitionistic mathematics, he meant the BHK. His goal was to realise the BHK in a formal system. In so doing he also clarified ideas presented earlier by Haskell Curry (1958) and W. W. Tait (1965).
  
  \vspace{40mm}

\end{frame}

\begin{frame}
  \frametitle{Brouwer-Heyting-Kolmogorov Interpretation}

  % This is a philosophical ideal. But vague.
  % What should such algorithms look like?
  Recall that intuitionistic proofs of the propositional connectives must be of the following form: 

  \vspace{0.5cm}

  \begin{center}
    \begin{tabular}{p{1.5cm}p{8cm}}
      $P \to Q$ & to prove an implication we must provide an algorithm for turning a proof of P into a proof of $Q$\\
      $P \lor Q$ & to prove a disjunction we must provide either a proof of P or a proof of Q. \\
      $P \land Q$ & to prove a conjunction we must provide both a proof of P and a proof of Q. \\
      $\lnot P$ &  to prove a negation we must provide an algorithm that turns a proof of P into a proof of $\bot$ 
    \end{tabular}
  \end{center}

  \vspace{0.5cm}

  This presentation is taken from the \href{https://plato.stanford.edu/entries/mathematics-constructive/}{Standford Encyclopedia of Philosophy} article by Bridges, Palmgren, and Ishihara.
\end{frame}

\begin{frame}
  \frametitle{BHK: Implication}

    To prove an implication we must provide an \underline{{\bf algorithm}} for turning a proof of P into a proof of $Q$.

    William Howard (following Curry 1958) knew the simply typed $\lambda$-calculus could provide a concrete meaning to the word \emph{algorithm} used in the BHK. 

    He observed that if the types $P,Q, P\to Q$ of the simply typed $\lambda$-calculus were thought of as propositions, then the derivation of a term $f : P \to Q$ is equivalent to an intuitionistic implicational proof of the proposition $P \to Q$. 
    
    Moreover, if we interpret a term $x : P$ to represent a proof of $P$ as a proposition, then $f : P \to Q$ really is a function that takes a proof of $P$ and, by beta reduction, will return a proof $Q$.
\end{frame}

\begin{frame}
  \frametitle{Example}

  $$\vdash \ P \to P$$

  \vspace{10mm}

  \begin{center}
    $\begin{array}{l c r}
      
      \begin{array}{c}
        \infer[\to, 1]{P \to P}
          {\infer[1]{P}{}}
      \end{array}

      &
      \hspace{10mm}
      &
      
      \begin{array}{c}
        \infer[\lambda, 1]{(\lambda \ x : P. \ x) \ : \ P \to P}
          {\infer[1]{p \ : \ P}{}}
      \end{array}

    \end{array}$
  \end{center}

  \vspace{25mm}
  
  The \textbf{I} combinator is a witness to the fact that $P \to P$ is a tautology.
\end{frame}

\begin{frame}
  \frametitle{Example}

  $$P \ \vdash \ Q \to P$$

  \vspace{10mm}

  \begin{center}
    $\begin{array}{l c r}
      
      \begin{array}{c}
        \infer[\to]{Q \to P}
          {\infer[]{P}{}}
      \end{array}

      &
      \hspace{10mm}
      &
      
      \begin{array}{c}
        \infer[\lambda]{(\lambda \ x : Q. \ p) \ : \ Q \to P}
          {\infer[]{p \ : \ P}{}}
      \end{array}

    \end{array}$
  \end{center}

  \vspace{25mm}
  
  We call the term $\lambda x : Q. \ p$ the proof-object of the corresponding natural deduction.
\end{frame}

\begin{frame}
  \frametitle{Curry-Howard Correspondence}

  Curry and Howard's observation is summarised in this table.

  \begin{center}
    \begin{tabular}{l|l}
      Natural Deduction & Simply Typed $\lambda$-calculus \\
      \hline
      Proposition $P$ & Type $P$ \\
      P $\to$ Q : Prop & P $\to$ Q : Type \\
      $\to$ Introduction & $\lambda$ Abstraction\\
      Modus Ponens & Function Application \\
      Proof of $P$ & Term $t$ of type $P$
    \end{tabular}
  \end{center}

  We can state the following concrete metatheorem connecting theorems of positive minimal \underline{implicational} logic and programs in the simply typed $\lambda$-calculus.

  {\bf Theorem}$$ \Sigma \ \vdash_{\text{PIL}} \alpha \ \ \ \leftrightarrow \ \ \ \Sigma \ \vdash_{\lambda_{\to}} t \ : \ \alpha$$

  This first appeared in Curry (1958) and in a form closer to our notation in Howard (published 1980, manuscript circulated 1969).
  % Curry-Howard is a bit richer than this, because it distinguishes between proofs!
  % It is not just that if one sequent is provable, then the other is; it's the each proof on one side corresponds to a proof on the other.
\end{frame}

\begin{frame}
  \frametitle{Example}

  $$ \vdash \ P \to (Q \to P)$$

  \vspace{1cm}

  \begin{center}
    $\begin{array}{c}
      
      \begin{array}{c}
        \infer[\to, 1]{P \to (Q \to P)}
          {\infer[\to]{Q \to P}
            {\cancel{\infer[1]{P}{}}}}
      \end{array}

      \vspace{1cm}

      \\
      
      \vspace{1cm}

      \begin{array}{c}
        \infer[\lambda, 1]{\lambda x : P. \ (\lambda y : Q. \ x) \ : \ P \to (Q \to P)}
          {\infer[\lambda]{(\lambda y : Q. \ p) \ : \ Q \to P}
            {\cancel{\infer[1]{p \ : \ P}{}}}}
      \end{array}

    \end{array}$
  \end{center}
  
  The \textbf{K} combinator is a proof-term (witness) of this theorem.
  
\end{frame}

\begin{frame}
  \frametitle{Illustration of Correspondence}

  $$ A \to B, \ \ B \to C \ \vdash A \ \to C$$
  
  % Write the ND in lecture first. 
  % Then go back over that and annotate with lambda terms. 
  
%  \begin{center}
%  	$\begin{array}{c}
%  		\infer[\to I,1]{A \to C}
%  			{\infer[\MP]{C}
%  				{\infer[\MP]{B}
%  					{\infer[1]{A}{}
%  					&
%  					A \to B}
%  				&
%  				B \to C}}
%  	\end{array}$  
%  \end{center}
  
  	\vspace{70mm}
  
\end{frame}

\begin{frame}
	\frametitle{Illustration of Correspondence}
	
	Reconstruct the proof corresponding to the following term: 
	$$\lambda f. \ \lambda g. \ g \ (f \ g) \ : \ ((A \to B) \to A) \to ((A \to B) \to B)$$
	
	% Types give the types of abs; these are local variables. 
	% Working inside out on the terms gives the steps in the proof.
	
	\vspace{60mm}
	
	\textbf{$\lambda$-terms encode proofs. They \underline{are} proofs.}

\end{frame}



\begin{frame}
  \frametitle{Proofs = Programs}

  Under this correspondence of types-as-propositions, the terms that inhabit the types are often referred to as \emph{proof objects}.

  We say a $\lambda$-term (program) of type $P$ is a proof object witnessing the proof of $P$ as a proposition.

  {\bf Question:} How does this compare to BHK interpretation of proofs of implication?

  \vspace{50mm}
\end{frame}

\begin{frame}
  \frametitle{Motivation}

  Curry and Howard showed positive minimal implication proofs correspond to programs in the simply typed $\lambda$-calculus. 
  
  In his paper, Howard (1980) extended the simply typed $\lambda$-calculus to include type constructors and destructors corresponding to the other propositional connectives. 

  This extended type theory is referred to as \emph{simple type theory}, to distinguish it from dependent type theory. We may also refer to it as \emph{Intuitionistic Type Theory.} 
  
  \vspace{40mm}
  
\end{frame}

\begin{frame}
  \frametitle{Curry-Howard Correspondence}

	We will give a type theoretic interpretation of each propositional connective with a type former, constructor, and destructor. Along with computation rules for the corresponding redex.

  \begin{center}
    \begin{tabular}{l|l}
      Logic & Type Theory \\
      \hline
      Proposition $P$ & Type $P$ \\
      Proof & Program \\
      $\to$ & Function type \\
      $\land$ &  \\
      $\lor$ & \\ 
      $\bot$ & \\
      $\lnot$
    \end{tabular}
  \end{center}

  We will follow a modern formulation of these ideas from \href{https://www.cs.kent.ac.uk/people/staff/sjt/TTFP/}{Type Theory and Functional Programming, Simon Thompson}. 
  
  \vspace{20mm}
  
\end{frame}

\begin{frame}
  \frametitle{Product Type: Formation}

  Given any two types $P,Q$ we may form another type $P \times Q$ : Type.
  
	\vspace{5mm}

    \begin{center}
  	$\begin{array}{c}
  		\infer[]{A \times B  \ : \ \text{Type}}
  			{A  \ : \ \text{Type}
  			\hspace{10mm}&\hspace{10mm}
  			 B  \ : \ \text{Type}}
  	\end{array}$  
  \end{center}
  
  \textbf{Examples}
  
  \vspace{50mm}
  
  \end{frame}
  
  
  \begin{frame}
  	\frametitle{Product Type: Constructor}  
  
    Given inhabited types $p : P$ and $q : Q$ we form a term of the product type as follows: 

  \begin{center}
    $\begin{array}{c}		
      \infer[\times]{(p,q) \ : \ P \times Q}
        {p \ : \ P \quad & \quad q \ : \ Q}	
    \end{array}$
  \end{center}

  To construct a term of type $P \times Q$ a program needs to provide a term $p :P$ {\bf and} a term $q : Q$. 
  
  \vspace{50mm}

\end{frame}

\begin{frame}
 \frametitle{Product Type: Destructor}

 The product type has two destructors that form terms of the component types. These are FST (FirST) and SND (SecoND). 

 \begin{center}
   $\begin{array}{c c c}
     \infer[\text{\fst}]{\fst \ (a,b) \ : \ A}{(a,b) \ : \ A\times B}

     &
     \quad
     &

     \infer[\text{\snd}]{\snd \ (a,b) \ : \ B}{(a,b) \ : \ A\times B}

   \end{array}$
 \end{center}

 With these new terms we have to say how computations work i.e. what are the $\beta$ reduction rules for $\fst, \snd$?

 \begin{center}
   $\fst (a,b) =_{\beta} a$ 

   $\snd (a,b) =_{\beta} b$ 
 \end{center}

 If these terms appear in any program, then they are $\beta$-redex that can be $\beta$-reduced according to these equations.
 
 \vspace{25mm}

\end{frame}


% At this point one might ask for the type of FST, SND, \times ... 
% Since we want one program FST to deal with all pair types, the program FST has 
% to be polymorphic. It needs to be open to the types that make up the pair. 
% Calling FST would look like: 

% FST TYPE1 TYPE2 (a:TYPE1, b:TYPE2) -> a:TYPE1

% We don't have the language to talk about passing types through expressions. 
% To do this one should talk about polymorphism and dependent type theory. 

\begin{frame}
  \frametitle{Example}

  Show that the following type is inhabited:

  $$ \vdash \ (A \times B) \to (B \times A)$$

  \vspace{0.5cm}

  \begin{center}
    $\begin{array}{c}
      \infer[\lambda, 1]{(\lambda y : A\times B. \ (\snd y) \ (\fst y)) \ : \ (A\times B)\to(B \times A)}
        {\infer[\times]{(\snd x, \fst x) \ : \ B \times A}
          {\infer[\snd]{\snd x \ : \ B}{\infer[1]{x \ : \ A\times B}{}} \quad & \quad \infer[\fst]{\fst x \ : \ A}{\infer[1]{x \ : \ A\times B}{}}}}
    \end{array}$
  \end{center}

  \vspace{5mm}

  {\bf Question:} If this proof is a program, then what does it do? 

  \vspace{30mm}

\end{frame}

\begin{frame}
  \frametitle{Product is Associative}

  Show that the following type is inhabited:
  $$ \vdash \ (A \times B) \times C \to A \times (B \times C)$$

  \vspace{70mm}


\end{frame}

\begin{frame}
  \frametitle{Currying}

  Show that the following type is inhabited:
  $$ \vdash \ (A \times B \to C) \to (A \to (B \to C))$$

  \vspace{70mm}


\end{frame}

\begin{frame}
  \frametitle{Coproduct Type: Formation}

  Given any two types $P,Q$ we may form another type $P + Q$ : Type
     \begin{center}
  	$\begin{array}{c}
  		\infer[]{A + B  \ : \ \text{Type}}
  			{A  \ : \ \text{Type}
  			\hspace{10mm}&\hspace{10mm}
  			 B  \ : \ \text{Type}}
  	\end{array}$  
  \end{center}

	\textbf{Examples}

\vspace{50mm}
  
  \end{frame}
  
  \begin{frame}
  \frametitle{Coproduct Type: Constructors}
  
  There are two constructors for the coproduct of two types.

  \begin{center}
    $\begin{array}{c c c}
      \infer[\text{\inl}]{\inl \ p \ : \ P + Q}{p \ : \ P}

      &
      \quad
      &

      \infer[\text{\inr}]{\inr \ q \ : \ P + Q}{q \ : \ Q}

    \end{array}$
  \end{center}

  To construct a term of type $P + Q$ a program has to provide either a term $p : P$ {\bf or} a term $q : Q$ and tag which one it belongs to. 

  % data Either A B = Left a | Right b -- Haskell syntax for coproduct of A and B. 

  % The coproduct of two types is a "loose bag" labelled A+B. In order to put something in the bag it must either be from A or B and it must be labelled as to which it came from. 

	\vspace{50mm}

\end{frame}

\begin{frame}
  \frametitle{Coproduct Type: Elimination}

  The coproduct has one destructor which takes into account the two possible forms a term $x : P + Q$ could take. 
  
  \vspace{5mm}

  \begin{center}
    $\begin{array}{c}
      \infer[\sumElim]{\sumElim x \ a \ b \ : \ R}{x \ : \ P + Q \quad & \quad a \ : \ P \to R \quad & \quad  b \ : \ Q \to R}
    \end{array}$
  \end{center}

\vspace{5mm}

  There are two possibilities which correspond to whether the term $x$ of $P+Q$ is of the form $x = \inl p$ or $x = \inr q$. 

  \begin{center}
    $\sumElim (\inl p) \ a \ b =_{\beta} a \ p$ 

    $\sumElim (\inr q) \ a \ b =_{\beta} b \ q$
  \end{center}

  If these terms appear in any program, then they are $\beta$-redex that can be $\beta$-reduced according to the these equations. When writing a program with input $t : P+Q$ we have to know what type the element $t$ came from: either $P$ or $Q$. The two constructors ``inl'' and ``inr'' act as tags for the program to know how to treat $t : P+Q$. 
\end{frame}

\begin{frame}
  \frametitle{Example}

  Show that the following type is inhabited:
  $$ \vdash \ (A \times B) \to (A + B)$$
  

  \vspace{50mm}
  Can you give another proof?
\end{frame}

% \begin{frame}
%   \frametitle{Dual Constructions}

%   The product and coproduct are dual constructions. 
%   % Product types are often called Pi Types.
%   % Coproducts are often called Sigma (Sum) Types.

%   \vspace{0.5cm}

%   \begin{center}

%     $\begin{array}{c c}

%       \begin{tikzpicture}
%         \node (A) at (0,0) {$A \times B$};
%         \node (B) at (-2,0) {$A$};
%         \node (C) at (2,0) {$B$};
%         \node (D) at (0,1) { PAIR };
%         \path[->]
%         (A) edge node[above] {\fst} (B)
%         (A) edge node[above] {\snd} (C)
%         (D) edge node[right] { \ } (A)
%         ;
%       \end{tikzpicture}

%       \hspace{0.5cm}

%       &

%       \begin{tikzpicture}
%         \node (A) at (0,0) {$A + B$};
%         \node (B) at (-2,0) {$A$};
%         \node (C) at (2,0) {$B$};
%         \node (D) at (0,1) { cases };
%         \path[->]
%         (B) edge node[above] {inl} (A)
%         (C) edge node[above] {inr} (A)
%         (A) edge node[right] { \ } (D)
%         ;
%       \end{tikzpicture} 
%     \end{array}$
%   \end{center}

%   \vspace{3cm}

%     The product has one constructor and two destructors. 

%     The coproduct has two constructors and one destructor.

% \end{frame}

\section{Simple Type Theory}

\begin{frame}
  \frametitle{Curry-Howard Correspondence}

  \begin{center}
    \begin{tabular}{l|l}
      Logic & Type Theory \\
      \hline
      Proposition $P$ & Type $P$ \\
      Proof & Program \\
      $\to$ & Function type \\
      $\to I$ & $\lambda$ \\
      $\MP$ & app \\
      $\land$ & $\times$ \\
      $\land E_{l}$ & fst \\
      $\land E_{r}$ & snd \\
      $\lor$ & $+$\\ 
      $\lor I_{l}$ & inl \\
      $\lor I_{r}$ & inr \\
      $\lor E$ & cases  
    \end{tabular}
  \end{center}
  
  See \href{https://www.cs.kent.ac.uk/people/staff/sjt/TTFP/}{Type Theory and Functional Programming, Simon Thompson} and \href{https://people.cs.nott.ac.uk/psztxa/publ/fomus19.pdf}{Naive Type Theory, Thorsten Altenkirch} for more details.
\end{frame}

\begin{frame}
  \frametitle{Terms and Proofs}

  Inhabited types of so-called \emph{simple type theory} are therefore in one-to-one correspondence with the theorems of positive minimal logic. 

  $$ \vdash_{\text{STLC}} P \hspace{1cm} \text{if and only if } \hspace{10mm} \vdash_{\text{ML}} P$$
  
  Moreover, each natural deduction of a theorem $P$ corresponds to a different $\lambda$-term. This isomorphism is not just capturing whether there is a natural deduction, or typing derivation, it is transferring specific deductions to the other side. In this sense the correspondence is proof-relevant. The proofs matter and are transported from logic to type theory and back again.
  
  \textbf{This correspondence is showing us that the way we break down hypotheses and build conclusions in a proof is the same process as breaking down and building data when writing programs!}

\end{frame}

% \begin{frame}
%   \frametitle{Example}
%   % Pick an intuitionistic tautology and show that this type is inhabited.
%   Show that the following type is inhabited:
%   $$ \vdash \ A \to (B \to A)$$ 

%   \vspace{6cm}

% \end{frame}

\begin{frame}
  \frametitle{Example}
  % Pick a contingent statement and show that this type is uninhabited.
  Show that the following type is uninhabited:
  $$ \cancel{\vdash} \ (A + B) \to B$$ 
  
  % (i) inl a : A + B... no B in sight 
  % (ii) Consider the following logical theorem. 
  % (iii) not a classical tautology, therefore not provable with classical logic.

  \vspace{6cm}

\end{frame}

% \begin{frame}
%   \frametitle{Example}
%   % Pick a contradiction and show that this type is uninhabited.
%   Show that the following type is uninhabited:
%   $$ \cancel{\vdash} \ A \times \lnot A$$ 

%   \vspace{6cm}

% \end{frame}

\begin{frame}
  \frametitle{Curry-Howard Correspondence}

  There is a precise correspondence between typed programs and natural deductions in the positive part of minimal logic. 

  \vspace{5mm}

  Propositions are types. Proofs are programs. Propositional connectives are type formation rules. Rules of inference are term constructors/destructors. 

  \vspace{5mm}

  How far do these ideas extend beyond positive minimal logic? Is there a type corresponding to the proposition $\bot$? Or, the negation type? Can we make type theoretic sense of the propositional rules of inference ex falso and reductio ad absurdrum? 

\end{frame}

\begin{frame}
  \frametitle{Empty Type: Formation}

  We add to our type theory the type $\bot$ corresponding to the proposition denoted by the same symbol. 
  
  $$ \bot \ : \ \text{Type} $$

  Following the Curry-Howard correspondence:
  
  $$ \vdash t : P \hspace{1cm} \text{if and only if} \hspace{1cm} \vdash P$$
  
  If the type $\bot$ is generally inhabited, then it would necessarily be a theorem of propositional minimal logic. It is not a theorem of propositional minimal logic. Therefore, the type $\bot$ should be considered uninhabited. Hence we will refer to it at as the empty type.

  In other words, the type $\bot$ has {\bf no introduction rule.} 

\end{frame}

\begin{frame}
  \frametitle{Empty Type: Destructor}

  Destructors tell us how to write a program out of the given type. What do we need to provide in order to write a program out of the empty type? Nothing! There is no input to deal with, so we simply return what ever we want!

  \begin{center}		
		$\begin{array}{c}		
		\infer[\bot \text{E}]{\abort_{A}(t) \ : \ A}
		{\begin{array}{c} t \ : \ \bot \end{array}}
		\end{array}$
	\end{center}

  If a program context $\Sigma$ allows for the derivation of a term $t$ of type $\bot$, then this rule states that the program can construct a term of any type. This term records the derivation, $t$, of the type $\bot$ and tags it with ``abort'' to acknowledge this. That's all it does. There are no computation rules for the constructor $\abort_{T}$ for any type $T$. We may think of $\abort_{A}(t)$ as a record that the program has crashed. The type of an error. 
    
  This is the type theoretic interpretation of Ex Falso. 

\end{frame}

\begin{frame}
  \frametitle{Negation Type}

  Propositions of the form $\lnot P$ were defined in terms of $\bot$ as 

  $$\lnot P :\equiv P \to \bot$$

  In our simple type theory then, the type $\lnot P$ is defined to be a shorthand for the function type $P \to \bot$.  

  \vspace{4cm}

\end{frame}

\begin{frame}
  \frametitle{Example}

  Determine a proof-object that witnesses a proof of the theorem
  $$ \vdash \ (P \to Q) \to \lnot Q \to \lnot P$$

  \vspace{6cm}

\end{frame}

\begin{frame}
  \frametitle{Example}

  Derive a proof object witnessing the proof of the sequent: 
  $$ \lnot A \lor B \ \vdash \ A \to B$$

  \vspace{5cm}

\end{frame}

\begin{frame}
  \frametitle{Example}

  Derive a proof object witnessing the proof of the sequent: 
  $$ \vdash \ \lnot(Q \to P) \to (P \to Q)$$

  \vspace{5cm}

\end{frame}

\begin{frame}
  \frametitle{Curry-Howard Correspondence}

	We have therefore a type theoretic interpretation of intuitionistic propositional logic. Can this be extended to classical logic?

  \begin{center}
    \begin{tabular}{l|l}
      Logic & Type Theory \\
      \hline
      Proposition $P$ & Type $P$ \\
      Proof & Program \\
      $\to$ & Function type \\
      $\to I$ & $\lambda$ \\
      $\MP$ & app \\
      $\land$ & $\times$ \\
      $\land E_{l}$ & fst \\
      $\land E_{r}$ & snd \\
      $\lor$ & $+$\\ 
      $\lor I_{l}$ & inl \\
      $\lor I_{r}$ & inr \\
      $\lor E$ & cases  \\
      Falsum & Empty Type \\
      XF & $\bot$E
    \end{tabular}
  \end{center}

\end{frame}

\begin{frame}
  \frametitle{Morally: CHI as BHK}

  The Curry-Howard Isomorphism can be thought of as a formal system for interpreting the BHK-interpretation of the logical connectives. 

  Recall the BHK interpretation for proofs of disjunction 

  \begin{center}
    \begin{tabular}{p{1.5cm}p{8cm}}
      $P \lor Q$ & to prove a disjunction we must provide either a proof of P or a proof of Q. 
    \end{tabular}
  \end{center}

  If we could extend the propositions-as-types idea to include classical logic, then types of the form $P + \lnot P$ would be inhabited for each proposition $P$. Following the classical proof of LEM given earlier in the course, these proof-objects could not give us a proof befitting the BHK i.e. would not tell us whether the term is of the form $\inl P$ or $\inr \lnot P$.
  % So something has to give if we extend this to classical logic. 

\end{frame}

\begin{frame}
  \frametitle{Continuations}

  % The author of this .tex file knows nothing about the paper. 
  % This slide is here to communicate the existence of the idea to the student.

  In 1990 Timothy Griffin wrote the paper \emph{A Formulae-as-Types Notion of Control}. In this paper he proves that the programming language \emph{Typed Idealized Scheme} allows for programs to be extracted from classical proofs.

  \vspace{0.5cm}

  He states:

  \emph{It is shown that classical proofs possess computational content when the notion of computation is extended to include explicit access to the current control context.}

 More about this in Chapter 6 of S\o rensen and Urzyczyn, \emph{Lectures on the Curry-Howard Isomorphism}.

\end{frame}

\begin{frame}
  \frametitle{Double Negation Translation}

  For a different point-of-view on the computational content of classical theorems, recall that we can characterise the barrier between classical and intuitionistic logic as the use of double negation elimination.
  $$\text{{\bf Meta-Theorem:}} \hspace{0.5cm} \Sigma \vdash_{C} \ P \hspace{0.5cm} \text{ if and only if } \hspace{0.5cm} \Sigma \vdash_{I} \lnot\lnot P$$

  For any classical theorem $P$, there is a proof-object witnessing an intuitionistic proof of $\lnot \lnot P$. 

  \vspace{0.5cm}

  In this sense there is computational content, consistent with the Curry-Howard correspondence, in every classical theorem up-to the point one uses double negation elimination or some other equivalent mode of classical reasoning.
  % This is different to Griffin's comment about continuations. 

\end{frame}

\begin{frame}
  \frametitle{Example}

  Write a proof-object witnessing the intuitionistic theorem: $$ \vdash \ \lnot \lnot (P \lor \lnot P)$$
  
  % Write the natural deduction first. 
  % Annotate it with terms. 
  % Highlight the proof-term of notnot-LEM.

  \vspace{60mm}
  
  {\bf One \underline{cannot} \emph{refute} the law of excluded middle.}
\end{frame}

\section{Proof Assistants}

\begin{frame}
  \frametitle{Mathematical Proofs?}

  Can these languages check proofs of mathematical theorems? 
  
  We have seen that first-order predicate logic is enough to express some areas of mathematics and prove \underline{mathematical} theorems. Therefore, an interpretation of first-order logic in the theory of types would provide a language for doing mathematics where (i) theorem statements are types, and (ii) proofs of those theorems are terms of the corresponding type. 
  $$\forall x \ : \ \mathbb{N}, \ s(x) = x + 1 \ : \ \text{Type}$$  % Give a computational interpretation of this. 
  Per Martin-L\"{o}f (student of Andrey Kolmogorov, K of the BHK) and others have developed \emph{dependent type theory} which does this. Moreover modern programming languages have implemented these ideas in what are known as \emph{proof assistants}.

  % Mathematicians can now write and check their theorems and proofs on a computer using these languages!

\end{frame}

\begin{frame}
  \frametitle{Do Mathematicians Do/Know This?}

  % This slide is spoken from a point-of-view that is not exactly my own... 
  % I don't believe it... but I see the point of people who make it. 
  Mathematicians might be forgiven for not wanting to do natural deductions to prove all their theorems; it is cumbersome and the interesting ideas are often hidden in a sea of uninteresting details. 

  % I'd say the ideas aren't hidden. The mathematician would have all the ideas to come up with the theorem statement and proof technique in the first place. The ideas are all still there, it's just that they aren't explicitly stated in this presentation of the proof. 

  However, the level of certainty this method provides is a feature that (I believe) should be built into the way we do mathematics. Plus, those that have worked in this direction have claimed to find it an enriching (not to mention fun!) process. 
  % Peter Scholze, Kevin Buzzard, Thomas Hales... 

  We might be at an inflection point for the rate of adoption of these formal methods. 
  
  \vspace{40mm}
\end{frame}

\begin{frame}
  \frametitle{How to Increase Adoption?}

  Some of the primary difficulties for adoption of proofs-as-programs:

  \begin{itemize}
    \item Type theory is unusual to mathematicians, 
    \item Lots of boring steps,
    \item Programming language design, and 
    \item UX Design.
  \end{itemize}

  Fundamentally then much of the problem is a software engineering problem! 

  Full adoption will require the collaboration of mathematicians, programming language theorists, and software engineers. Moves are being made in this direction!

  % Still at the research level
  % Haskell, Agda, Coq, Isabelle, HoL, Lean... 
  
  \vspace{30mm}

\end{frame}

\section{Course Summary}

\begin{frame}
  \frametitle{Hilbert's Program}

  We set out to see what came of Hilbert's Program to determine whether mathematics could be put on firm foundations. To show mathematics is: 

  \begin{itemize}
    \item Complete,
    \item Consistent, 
    \item Decidable by an algorithm. 
  \end{itemize}

  G\"{o}del showed that PA is not completable and that there can be no finitary proof that PA is consistent. 

  Turing and Church showed that decidability by an algorithm is impossible for theorems of first-order logic. 

  All of Hilbert's questions were answered in the negative... 
\end{frame}

\begin{frame}
  \frametitle{Unexpected Landmarks}

  ... But a great number of interesting ideas were developed along the way that have had an effect on mathematics and society. 

  These theoretical developments have all happened in parallel with the engineering of machines that can carry out computation at a great scale. Many of the mathematical models of computation fed into both the design of machines and the design of the languages we use to talk to the machines!

  Although Turing and Church showed that we can't have an algorithm for deciding theoremhood, we do now have machines that can help us write and check the proofs of theorems. Moreover, parts of this process \underline{can} be automated by these machines. 
\end{frame}


\begin{frame}
	\frametitle{Further Reading}
	
    This lecture was prepared with the aid of the following references. 
    These should be consulted for further detail on the topics. 
    
    Stanford Encyclopaedia of Philosophy Articles: \href{https://plato.stanford.edu/entries/type-theory/}{Type Theory}, \href{https://plato.stanford.edu/entries/type-theory-intuitionistic/}{Intuitionistic Type Theory}, and \href{https://plato.stanford.edu/entries/mathematics-constructive/}{Constructive Mathematics}. 
    
    \href{https://www.cs.kent.ac.uk/people/staff/sjt/TTFP/}{Type Theory and Functional Programming, Simon Thompson}
    
    \href{https://people.cs.nott.ac.uk/psztxa/publ/fomus19.pdf}{Naive Type Theory, Thorsten Altenkirch}
    
    Each of these are freely available on the world wide web.
    
    \vspace{50mm}    
	
\end{frame}
\end{document}
